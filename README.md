# cell-live-dead-classifier
CNN classifier for distinguishing live vs. dead cells using microscopy images. Includes training, prediction, and dataset preparation.
---
ğŸ”¬ Clasificador de CÃ©lulas Vivas y Muertas con Redes Neuronales (CNN)

Este proyecto utiliza visiÃ³n por computadora y redes neuronales convolucionales (en inglÃ©s, CNN) para clasificar imÃ¡genes microscÃ³picas de cÃ©lulas como vivas o muertas.

Las CNN es como una serie de filtros o lupas que miran una imagen y van detectando:

bordes,

texturas,

formas,

patrones repetidos,

regiones importantes.

El objetivo es demostrar cÃ³mo la inteligencia artificial puede analizar imÃ¡genes biomÃ©dicas de forma automÃ¡tica.

Se incluye:

Script para entrenar un modelo desde cero

Script para hacer predicciones

GuÃ­a completa para usarlo en Visual Studio Code (VS Code)

Dataset pÃºblico utilizado

ExplicaciÃ³n clara del funcionamiento del sistema
---
ğŸ“ 1. Dataset Utilizado

Este proyecto utiliza el dataset pÃºblico:

ğŸ‘‰ Cell-Dataset â€“ por Max Kudi
ğŸ”— https://github.com/maxKudi/Cell-Dataset

Contiene imÃ¡genes reales de cÃ©lulas clasificadas como:

live/ â†’ cÃ©lulas vivas

dead/ â†’ cÃ©lulas muertas

Para usarlo en este proyecto se reorganizÃ³ de la siguiente forma:
```
data/
 â”œâ”€â”€ train/
 â”‚     â”œâ”€â”€ dead/
 â”‚     â””â”€â”€ live/
 â””â”€â”€ val/
       â”œâ”€â”€ dead/
       â””â”€â”€ live/
```

Esto permite que TensorFlow asigne:

Clase 0 â†’ dead

Clase 1 â†’ live
---
ğŸ§  2. Arquitectura del Modelo

ğŸ“Œ 1. Rescaling (normalizaciÃ³n)

Antes de analizar la imagen, se normalizan sus valores a un rango entre 0 y 1.
Esto ayuda a que la red aprenda de forma mÃ¡s estable.

ğŸ“Œ 2. Capas Convolucionales + MaxPooling2D

Estas son las capas principales de la CNN:

ğŸ”¹ Conv2D (32 filtros)

Busca patrones simples como lÃ­neas o bordes.

ğŸ”¹ MaxPooling2D

Reduce el tamaÃ±o de la imagen para quedarse solo con la informaciÃ³n mÃ¡s importante.

Este bloque se repite tres veces, aumentando la cantidad de filtros:

Conv2D (32 filtros) â†’ patrones simples  
Conv2D (64 filtros) â†’ patrones mÃ¡s complejos  
Conv2D (128 filtros) â†’ detalles avanzados de estructuras celulares


Cada capa se vuelve mÃ¡s â€œinteligenteâ€, detectando patrones mÃ¡s especÃ­ficos de las cÃ©lulas.

ğŸ“Œ 3. Flatten

Transforma la informaciÃ³n de las imÃ¡genes (que es 2D) en un vector (1D) para poder enviarlo a las capas finales de decisiÃ³n.

ğŸ“Œ 4. Dense(128) + ReLU

Una capa totalmente conectada que funciona como el â€œjuezâ€ principal.
AquÃ­ la red combina todos los patrones aprendidos para tomar decisiones.

ReLU es una funciÃ³n que ayuda a que el modelo aprenda relaciones mÃ¡s complejas.

ğŸ“Œ 5. Dropout (0.5)

Apaga aleatoriamente el 50% de las neuronas en esta capa durante el entrenamiento.

Esto evita que el modelo â€œmemoriceâ€ las imÃ¡genes y lo obliga a generalizar mejor.

ğŸ“Œ 6. Dense(1) + Sigmoid â†’ salida final

Esta es la capa mÃ¡s importante.

Tiene 1 sola neurona, porque solo necesitamos una respuesta:
Â¿EstÃ¡ viva la cÃ©lula? SÃ­ o no.

La funciÃ³n Sigmoid convierte la salida en un nÃºmero entre 0 y 1.

Ese nÃºmero se interpreta como:

â†’ Probabilidad de que la cÃ©lula estÃ© viva

Ejemplos:

0.85 â†’ 85% de probabilidad de ser â€œvivaâ€

0.10 â†’ 10% de probabilidad de ser â€œvivaâ€ (es decir, estÃ¡ muerta)

0.50 â†’ la red no estÃ¡ segura

ğŸ“Š CaracterÃ­sticas del modelo
âœ” binary_crossentropy como funciÃ³n de pÃ©rdida

Sirve para problemas donde solo hay dos clases: viva / muerta.

âœ” adam como optimizador

Es un algoritmo que ajusta los parÃ¡metros del modelo para que aprenda lo mÃ¡s rÃ¡pido y estable posible.

âœ” TamaÃ±o de imagen: 128Ã—128 px

Todas las imÃ¡genes se redimensionan a este tamaÃ±o antes de entrenar.

âœ” Salida del modelo

Un nÃºmero entre 0 y 1 que representa la probabilidad de que la cÃ©lula estÃ© viva.
---
ğŸ‹ï¸â€â™‚ï¸ 3. Entrenamiento del Modelo

El entrenamiento se realiza con el archivo:

```
cnn_ldc.py

```

Para entrenarlo:

```

python cnn_ldc.py

```

El script:

Carga las imÃ¡genes del dataset

Aplica data augmentation (rotaciÃ³n, zoom, flip)

Normaliza las imÃ¡genes (con Rescaling(1/255))

Entrena durante 15 Ã©pocas

Guarda el modelo como:

modelo_ldc_live_dead.h5

---

ğŸ” 4. PredicciÃ³n sobre Nuevas ImÃ¡genes

Para clasificar una imagen se usa:

predict_ldc.py


Ejemplo:

python predict_ldc.py


Salida esperada:

Imagen: 2.png
PredicciÃ³n: live
Confianza: 0.91

ğŸ”¥ Importante

El modelo ya normaliza internamente las imÃ¡genes con Rescaling(1/255).
Por lo tanto, NO debes normalizar nuevamente en la fase de predicciÃ³n.
(Este fue un bug original que ya estÃ¡ corregido.)

---
ğŸ§  Diagrama de la Arquitectura del Modelo (explicaciÃ³n visual)


                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     Imagen de entrada    â”‚
                        â”‚        128 Ã— 128 Ã— 3     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Rescaling (normaliza)  â”‚
                       â”‚   Valores 0â€“255 â†’ 0â€“1    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Primera etapa de aprendizaje â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                                                                           â”‚
          â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
          â”‚   â”‚   Conv2D     â”‚     â”‚   Conv2D     â”‚     â”‚   Conv2D     â”‚              â”‚
          â”‚   â”‚ (32 filtros) â”‚ â†’   â”‚ (64 filtros) â”‚ â†’   â”‚ (128 filtros)â”‚              â”‚
          â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚
          â”‚          â”‚                    â”‚                    â”‚                      â”‚
          â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                 â”‚
          â”‚   â”‚ MaxPooling  â”‚     â”‚ MaxPooling  â”‚     â”‚ MaxPooling  â”‚                 â”‚
          â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
          â”‚                                                                           â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                     â”‚
                                     â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚    Flatten     â”‚
                           â”‚ (pasa a 1D)    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Dense (128) + ReLU    â”‚
                       â”‚ Toma decisiones        â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Dropout (0.5)        â”‚
                       â”‚ Evita sobreajuste      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚          Dense (1) + Sigmoid              â”‚
                â”‚   Salida entre 0 y 1 = probabilidad de    â”‚
                â”‚         que la cÃ©lula estÃ© viva           â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Resultado final         â”‚
                        â”‚  Ej: 0.87 = 87% viva     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

